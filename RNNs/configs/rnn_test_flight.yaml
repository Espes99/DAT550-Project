test_flight: true

preprocess:
  max_len: 350

training:
  epochs: 5
  lr: 0.01
  batch_size: 8
  early_stopping: false

  scheduler:
    name: "ReduceLROnPlateau" # only option as of now
    mode: "max"
    factor: 0.5
    patience: 1
    verbose: true

model:
  rnn_type: "lstm" #lstm or gru
  bidirectional: true
  attention_layer: "custom" # "none" as a string to disable
  return_attn_weights: true
  num_layers: 1
  dropout: 0.1
  hidden_dim: 16

embedding:
  embedding_dim: 50 # 50, 100, 200, 300 / for fasttext embedding_dim will default to 300 since thats the only one
  embedding_type: "random"
  freeze: True

batch_size: 64
output_dir: outputs/test/lstmBiCustomGlove
log_dir: logs/test/lstmBiCustomGlove
use_tensorboard: false
evaluate_on_test: false